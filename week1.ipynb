{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Quality Report of credit_risk csv file\n",
    "\n",
    "Data quality is a measure of a data set's condition based on factors such as accuracy, completeness, consistency, reliability and validity.\n",
    "\n",
    "Introduction:\n",
    "This report aims to identify and address data quality issues in the \"credit_risk.csv\" dataset. The dataset contains information related to credit risk assessment.\n",
    "\n",
    "**Data Description:**\n",
    "The dataset consists of several columns including 'Income', 'Amount', and additional columns related to credit risk assessment.\n",
    "\n",
    "**Data Quality Issues:**\n",
    "\n",
    "1. **Missing Values:**\n",
    "   - The code snippet does not explicitly handle missing values. Further investigation is required to identify and address missing values properly.\n",
    "\n",
    "2. **Outliers:**\n",
    "   - Outliers were identified in the 'Income' and 'Amount' columns using the IQR method. Outliers can potentially impact the accuracy of statistical analysis and machine learning models.\n",
    "\n",
    "3. **Data Transformation Issues:**\n",
    "   - The code snippet attempts to handle outliers; however, the code for filtering out outliers may not be applied correctly.\n",
    "\n",
    "4. **Data Cleaning:**\n",
    "   - Missing values handling is mentioned but is currently commented out. It is essential to handle missing values appropriately before model training to avoid biased results.\n",
    "\n",
    "**Recommendations:**\n",
    "- Conduct a thorough analysis of missing values in the dataset and implement appropriate strategies for handling them.\n",
    "- Review the code for outlier detection and ensure that outliers are handled effectively without losing important data points.\n",
    "- Consider adding data validation steps to ensure the accuracy and reliability of the dataset before proceeding with modeling.\n",
    "\n",
    "**Conclusion:**\n",
    "Addressing data quality issues is crucial for ensuring the reliability and accuracy of analyses and models built on the dataset. By implementing proper data cleaning and preprocessing steps, we can enhance the quality of the dataset and improve the outcomes of any subsequent analyses.\n",
    "\n",
    "---\n",
    "\n",
    "This report highlights the importance of addressing data quality issues in the \"credit_risk.csv\" dataset and provides recommendations for improving the quality of the data for accurate and reliable analysis.\n",
    "\n",
    "Please adjust the recommendations and conclusions based on the specific details of your dataset and analysis requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('credit_risk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(20,15)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify missing values(during splitting the missing values can be handled)\n",
    "#missing_values = data.isnull().sum()\n",
    "#print(\"Missing values per column:\")\n",
    "#print(missing_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
